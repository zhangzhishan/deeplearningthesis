# 备用的文字
## 深度学习研究综述
The depth of learning in the signal processing application object not only contains voice, image and video, also contains text, language and the transmission of human semantic information.
Deep learning has been successfully applied to multiple pattern classification issues. Although this area is in the early stages of development, its development will undoubtedly have an impact on machine learning and artificial intelligence systems. At the same time, it still has some specific tasks that are not suitable for processing, such as language recognition, and the characteristics of generating pre-training extraction can only describe potential speech changes, and do not contain enough distinguishing information between different languages; iris recognition and so on Samples only contain a single sample of the model classification problem is not a very good task.
There is still a lot of work to study in depth. Whether the model has other more effective and theoretical basis of the depth of the model learning algorithm to explore the new feature extraction model is worthy of in-depth study of the content. In addition, an effective parallel training algorithm is also worthwhile to study a direction. It is difficult to perform parallel training in multi-computer based on the stochastic gradient optimization algorithm based on minimum batch processing. The usual way is to use the graphics processing unit to speed up the learning process, whereas a single machine GPU does not apply to large-scale data identification or similar task data sets. In the depth of learning application development, how to fully and rational use of deep learning in enhancing the performance of traditional learning algorithms is still the focus of the current research in various fields.
The concept of deep learning is derived from the study of artificial neural networks, and the multi-layer multilayer sensor (MLP) is a deep learning structure. Depth learning creates a more abstract high-level representation (attribute class or feature) by combining low-level features to discover the distributed feature representation of the data [1]. BP algorithm as a traditional training multi-layer network of the typical algorithm, in fact, only for several layers of the network, the training method has been very ideal [2]. Depth structure (involving multiple non-linear processing unit layers) The local minimum in the non-convex target cost function is the main source of training difficulties.
At present, most of the classification and regression methods are shallow structure algorithms. The limitation is that the limited ability of complex functions is limited in the case of finite samples and computational units. The generalization ability of complex classification problems is restricted [2]. In-depth learning can be achieved by studying a deep nonlinear network structure, implementing complex function approximation, characterizing the distributed representation of input data, and demonstrating the powerful ability to learn the essential characteristics of data sets from a small number of samples [1, 10].
BP algorithm is a classical gradient descent and a random selection of the initial value of the multi-layer network training algorithm, but the input and output nonlinear mapping between the network error function or energy function space is a non-linear space with multiple points , The search direction is only to make the network error or energy to reduce the direction, which often converge to the local minimum, and with the network layer increase situation is more serious. The theory and experiment show that the BP algorithm is not suitable for training the depth structure with multiple hidden layer elements [15]. This reason hinders the development of deep learning to a certain extent and transfers most of the machine learning and signal processing studies from the neural network to the relatively easy training shallow learning structure.
Inspired by the structure of the visual system, when a neuron with the same parameters is applied to the different positions of the previous layer, a transformation invariant feature is obtained. Later, LeCun et al. Used this idea to design and train CNNs using the BP algorithm. CNNs as a depth learning framework is based on minimizing the requirements of preprocessing data. By the early time delay neural network, CNNs reduce the complexity by sharing time domain weights. CNNs are a topological structure that uses spatial relations to reduce the number of parameters to improve general forward BP training and obtain better performance in multiple experiments [6]. A small portion of the image in the CNNs called the localized region is the lowest input of the hierarchical structure. The information is conveyed through different levels of the network, so that significant features of the observed data for translation, scaling and rotation can be obtained at each layer.
Document [6,2] describes the application of CNNs in handwriting recognition in the MNIST database. As shown in Fig. 4, essentially, the input pattern is convoluted with a series of trained filter coefficients. After the additive bias and compression, the feature normalization, etc., the initial stage is accompanied by further down- Cx) to provide robustness to the spatial variation; the downsampled feature map is weighted by the adjustable offset and eventually passed the activation function. Combining multiple of the above mapping layers (Figure 5) can obtain inter-layer relationships and spatial information so that CNNs are suitable for image processing and understanding. Domestic scholar Xia Dingyin [23] will apply this network to the network image annotation. Recent CNNs have been used in problems including different machine learning, including face detection, file analysis and voice detection.
##  叶片



C is called a convolution layer, also called a feature extraction layer, with the input of each neuron connected to the previous receptive field [8] and extracting the local feature. Once the local feature is After extraction, its positional relationship with other features is also determined. There are several different two-dimensional feature graphs in the C layer. A feature map is a feature that extracts a variety of different features. When extracting features, the weights of the same feature graph are shared, that is, using the same convolution kernel, the different feature graphs use different convolution cores. The C layer preserves the different local features so that the extracted features have a rotation and a translational invariance. The layer identified by S is a sub-sampling layer, also called a feature map layer, which is responsible for sub-sampling the features obtained by the C layer so that the extracted features have scaled invariance. S layer just do a simple scaling mapping, the need to train the neuron weight is relatively small, the calculation is relatively simple. In the CNN at the end of the general connection with several full connection layer, the final number of output nodes is the number of classification goals, the purpose of training is to make CNN output as close as possible to the original label.

First, assume that the input blade image size is 64 × 64 gray image, on the basis of the design of the plant leaf recognition CNN framework shown in Figure 4.
A detailed description of the CNN framework for plant leaf recognition is as follows:
(1) input. When the original image is not a grayscale image, the gray is first grayed out; when the size is not 64 × 64, the bilinear interpolation algorithm is used to scale the image to ensure the input requirement is satisfied.
(2) C1 layer. C1 is a feature extraction layer, it obtained 12 60 × 60 size of the two-dimensional feature map. In fact, it is obtained by a 5 × 5 size convolution kernel. The size of the convolution kernel determines the size of a neuron's sensory field. When the convolution kernel is too small, it can not extract the effective local features. When the convolution kernel is too large, the complexity of the extracted features may be far more than the convolution kernel The ability to express. Therefore, setting the appropriate convolution kernel is critical to improving the performance of the CNN, and it is also difficult to tune the CNN parameters. In the C1 using a 5 × 5 size convolution kernel, with 5 × 5 size convolution core to convolution 64 × 64 size of the picture, that is, traverse each 5 × 5 size of the unit, the final access to (64-5 +1) × (64-5 + 1) = 60 × 60 size of a feature map. Among them, the same feature map using the 5 × 5 convolution kernel are the same. As shown in Fig. 5, the feature map 1 and the feature map 2 extract two different characteristics, the dashed line and the solid line respectively represent different convolution cores; from the characteristic of Fig. 1, this means that the same convolution kernel is used The local block 1 and the local block 2 extract a feature that is placed in different neurons of the same feature map, respectively; from the local image block 1, it means that different convolution cores are used in the same local block extraction The two features were placed in neurons with different feature maps. The result of convolution is not directly stored in the C1 layer, but by an activation function to calculate, and then as a C1 layer of a neuron characteristics
Value, the activation function generally takes the Sigmoid function. In the actual operation, the convolution of the time but also with a bias item. For the image block x, the convolution is carried out using the convolution kernel w, the offset term is b, and the convolution operation of y is:
And the number of connections between the input layer and the C1: 312 × (60 × 60) = 1123200.
(3) S1 layer. S1 is the subsampling layer, which obtains 12 30 × 30 size feature maps. It is summed by multiplying all 2 × 2 sub-blocks x in C1 without multiplying by a weight w, plus a bias
Item b obtained. The sub-sampling calculation process is: y = Sigmoid [w · sum (xi) + b] (2)
Xi ∈ x
Because the size of the feature graph in C1 is 60 × 60, the resulting sub
The sampling result is a 30 × 30 characteristic subgraph. The next scaling factor is used for each sub-sampling layer. The reason for this is to control the rate at which the zoom is down, because the scaling is exponential, and the speed is too fast to mean that the extracted image is more rough and will be lost More image detail features. In CNN, the general scaling factor of 2 is enough. Each sub-sampling feature needs to train two parameters, S1 total of 12 × 2 = 24 parameters need training.
(4) C2 layer. C2 is also a feature extraction layer, it has a similar place with C1, but also a certain difference. The size of the convolution kernel used by C2 is 5 × 5, so the size of the feature graph is (30 - 5 + 1) × (30-5 + 1) = 26 × 26. As a result of the processing of C1 and S1, the receptive field covered by each of the neurons of S1 is equivalent to 10 × 10 of the original image (the convolution kernel of C1 is 5
× 5, the sampling sub-block size of S2 is 2 × 2,5 × 5 × 2 × 2 = 10 × 10). Now C2 and then through a 5 × 5 size of the convolution kernel to extract the characteristics of S1, and its sense of further expansion of the field, equivalent to the original image of 50 × 50. C2 has a total of 24 feature maps, doubled than C1, C1 through the input layer of a picture to obtain 12 mapping plane, and now C2 need from the S1 12 map mapping 24 features map, where a certain skill The Each of the feature graphs in C2 is convoluted by S1 or all of the feature graphs in S1, and then convolved. The reason why the entire feature map of S1 is always input is that the incomplete connection mechanism keeps the number of connections within a reasonable range; the most important thing is that it destroys the symmetry of the network, and the combination of different combinations Nature is a different feature. The strategy used in this paper is that if the feature map number of S1 is the factor of the C2 feature map number, then they are connected, such as the feature in S1. Figure 1 is connected to all the features in C2. All the numbers in C2 are even. S1 Figure 3 connected to C2 in all numbers can be divisible 3 feature map, and so on. For the jth feature graph C2j, j ∈ {1,2, ..., 24}, there are:
C2j = Sigmoid (ΣS1i + b) (3) i ∈ M
Where M = {i, j mod i == 0}, i ∈ {1,2, ..., 12}. At the next sub-sampling layer, use the same combination strategy.
(5) the remaining convolution layer and sub-sampling layer. The working principle of these layers is the same as the previous layer, but with the increase in depth,
Y = Sigmoid (wx + b)
( 1)
 Figure 5 C1 Number of parameters to be trained: 12 × (5 × 5 + 1) = 312
Convolution diagram
                                                                                            The classification of plant leaves based on convolution neural network
 Take the characteristics of more abstract, but also more expressive ability. After C1, S1, C2, S2 several layers of convolution and sampling, extracted features have been very expressive, but their abstraction is still not enough. In the experiment, when using only convolution neural networks with C1, S1, C2, S2, the correct classification accuracy is only about 40%. The depth of the convolution neural network is greatly improved by using the convolution neural network frame of Fig.4, which indicates that the depth has a great influence on the performance of the convolution neural network. The insufficient depth will weaken the feature extraction ability of the convolution neural network.
(6) output layer. The output layer is a fully connected layer with S3. S3 has 24 × 5 × 5 = 600 neurons, each neuron is connected with a neuron output, the output layer a total of 15 neurons (ie, the number of leaf types), so a total of 600 × 15 = 9000 connections. Here you can think of S3 as a 600-dimensional linear vector, and S3 to the output layer mapping is equivalent to the use of the vector classification, the classifier a total of 9000 parameters, it has a strong ability to describe.



## Unsupervised feature learning for audio classification using convolutional deep belief networks
In recent years, deep learning approaches have gained significant interest as a way of building hierarchical representations from unlabeled data. However, to our knowledge, these deep learning approaches have not been extensively stud- ied for auditory data. In this paper, we apply convolutional deep belief net- works to audio data and empirically evaluate them on various audio classification tasks. In the case of speech data, we show that the learned features correspond to phones/phonemes. In addition, our feature representations learned from unlabeled audio data show very good performance for multiple audio classification tasks. We hope that this paper will inspire more research on deep learning approaches applied to a wide range of audio recognition tasks.

1 Introduction

Understanding how to recognize complex, high-dimensional audio data is one of the greatest challenges of our time. Previous work [1, 2] revealed that learning a sparse representation of auditory signals leads to filters that closely correspond to those of neurons in early audio processing in mam- mals. For example, when sparse coding models are applied to natural sounds or speech, the learned representations (basis vectors) showed a striking resemblance to the cochlear filters in the auditory cortex. In related work, Grosse et al. [3] proposed an efficient sparse coding algorithm for auditory signals and demonstrated its usefulness in audio classification tasks.
However, the proposed methods have been applied to learn relatively shallow, one-layer representa- tions. Learning more complex, higher-level representation is still a non-trivial, challenging problem. Recently, many promising approaches have been proposed to learn the processing steps of the “second stage and beyond” [4, 5, 6, 7, 8]. These “deep learning” algorithms try to learn simple features in the lower layers and more complex features in the higher layers. However, to the best of our knowledge, these “deep learning” approaches have not been extensively applied to auditory data.
The deep belief network [4] is a generative probabilistic model composed of one visible (observed) layer and many hidden layers. Each hidden layer unit learns a statistical relationship between the units in the lower layer; the higher layer representations tend to become more complex. The deep belief network can be efficiently trained using greedy layerwise training, in which the hidden layers are trained one at a time in a bottom-up fashion [4]. Recently, convolutional deep belief networks [9] have been developed to scale up the algorithm to high-dimensional data. Similar to deep belief networks, convolutional deep belief networks can be trained in a greedy, bottom-up fashion. By applying these networks to images, Lee et al. (2009) showed good performance in several visual recognition tasks [9].
In this paper, we will apply convolutional deep belief networks to unlabeled auditory data (such as speech and music) and evaluate the learned feature representations on several audio classification tasks. In the case of speech data, we show that the learned features correspond to phones/phonemes. In addition, our feature representations outperform other baseline features (spectrogram and MFCC)
 1for multiple audio classification tasks. In particular, our method compares favorably with other state- of-the-art algorithms for the speaker identification task. For the phone classification task, MFCC features can be augmented with our features to improve accuracy. We also show for certain tasks that the second-layer features produce higher accuracy than the first-layer features, which justifies the use of deep learning approaches for audio classification. Finally, we show that our features give better performance in comparison to other baseline features for music classification tasks. In our experiments, the learned features often performed much better than other baseline features when there was only a small number of labeled training examples. To the best of our knowledge, we are the first to apply deep learning algorithms to a range of audio classification tasks. We hope that this paper will inspire more research on deep learning approaches applied to audio recognition tasks.
## Time series (particularly multivariate) classification
Abstract. Time series (particularly multivariate) classification has drawn a lot of attention in the literature because of its broad applica- tions for different domains, such as health informatics and bioinformatics. Thus, many algorithms have been developed for this task. Among them, nearest neighbor classification (particularly 1-NN) combined with Dynamic Time Warping (DTW) achieves the state of the art performance. However, when data set grows larger, the time consumption of 1-NN with DTW grows linearly. Compared to 1-NN with DTW, the traditional feature-based classification methods are usually more efficient but less effective since their performance is usually dependent on the qual- ity of hand-crafted features. To that end, in this paper, we explore the feature learning techniques to improve the performance of traditional feature-based approaches. Specifically, we propose a novel deep learn- ing framework for multivariate time series classification. We conduct two groups of experiments on real-world data sets from different application domains. The final results show that our model is not only more efficient than the state of the art but also competitive in accuracy. It also demonstrates that feature learning is worth to investigate for time series classification.
1 Introduction
As a large amount of time series data have been collected in many domains such as finance and bioinformatics, time series data mining has drawn a lot of attention in the literature. Particularly, multivariate time series classification is becoming very important in a broad range of real-world applications, such as health care and activity recognition [1–3].
In recent years, a plenty of classification algorithms for time series data have been developed. Among these classification methods, the distance-based method k-Nearest Neighbor (k-NN) classification has been empirically proven to be very difficult to beat [4, 5]. Also, more and more evidences have shown that the Dynamic Time Warping (DTW) is the best sequence distance measurement in most domains [4–7]. Thus, the simple combination of k-NN and DTW could
F. Li et al. (Eds.): WAIM 2014, LNCS 8485, pp. 298–310, 2014. ⃝c Springer International Publishing Switzerland 2014Time Series Classification Using MC-DCNN 299
reach the best performance of classification in most domains [6]. Other than sequence distance based methods, feature-based classification methods [8] follow the traditional classification framework. As is known to all, the performance of traditional feature-based methods depends on the quality of hand-crafted features. However, unlike other applications, it is difficult to design good features to capture intrinsic properties embedded in various time series data. Therefore, the accuracy of feature-based methods is usually worse than that of sequence distance based ones, particularly 1-NN with DTW method. On the other hand, although many research works use 1-NN and DTW, both of them cause too much computation for many real-world applications [7].
Motivation. Is it possible to improve the accuracy of feature-based methods? So that the feature-based methods are not only superior to 1-NN with DTW in efficiency but also competitive to it in accuracy.
Inspired by the deep feature learning for image classification [9–11], in this paper, we explore a deep learning framework for multivariate time series classifi- cation. Deep learning does not need any hand-crafted features by people, instead it can learn a hierarchical feature representation from raw data automatically. Specifically, we propose an effective Multi-Channels Deep Convolution Neural Networks (MC-DCNN) model, each channel of which takes a single dimension of multivariate time series as input and learns features individually. Then the MC-DCNN model combines the learnt features of each channel and feeds them into a Multilayer Perceptron (MLP) to perform classification finally. To estimate the parameters, we utilize the gradient-based method to train our MC-DCNN model. We evaluate the performance of our MC-DCNN model on two real-world data sets. The experimental results on both data sets show that our MC-DCNN model outperforms the baseline methods with significant margins and has a good generalization, especially for weakly labeled data.
The rest of the paper is organized as follows. Section 2 depicts the definitions and notations used in the paper. In section 3, we present the architecture of MC-DCNN, and describe how to train the neural networks. In section 4, we conduct experiments on two real-world data sets and evaluate the performance of each model. We make a short review of related work in section 5. Finally, we conclude the paper and discuss future work in section 6.

Time series classification is becoming very important in a broad range of real- world applications, such as health care and activity recognition. However, most existing methods have high computational complexity or low prediction accu- racy. To this end, we developed a novel deep learning framework (MC-DCNN) to classify multivariate time series in the paper. This model learns features from individual univariate time series in each channel automatically, and combines in- formation from all channels as feature representation at final layer. A traditional MLP is concatenated to perform classification. We evaluated our MC-DCNN model on two real-world data sets. Experimental results show that our MC- DCNN model outperforms the competing baseline methods on both data sets, especially, the improvement of accuracy on weakly labeled data set is significant. Also, we showed that 2-stages MC-DCNN is superior to 1-stage MC-DCNN. It provides the evidence that the deeper architecture can learn more robust high- level features, which is helpful for improving performance of classification.
There are several research directions for future work. First, in this paper we simply use the 1-stage and 2-stages feature learning for better illustration, and in the future we plan to study and extend other deep learning models for multivariate time series classification on more data sets. Second, we also intend to perform unsupervised algorithms on unlabeled data to pre-train the networks.
## RNN

Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score.
##  Over The Horizon Sky Wave Radar
Abstract— A software for the simulation of the coordinate registration technique for a pulse monostatic Over The Horizon Sky Wave Radar (OTH SWR) is presented. The main software features are described and the simulation results of a realistic propagation scenario are shown and discussed. The Sea/Land Transition Identification (SLTI) algorithm, developed by the same authors of this paper, has been applied assuming a 200 entries look-up table of ionospheric equiv- alent reflection height versus elevation angle. The SLTI algorithm performance is commented based on the error analysis of the ground range estimation of targets and the Sea/Land Transi- tions whose positions are known a priori.
1. INTRODUCTION
Recently, we introduced a Coordinate Registration (CR) method for an Over The Horizon Sky Wave Radar (OTH SWR) sensor based on the identification of Sea/Land transitions (SLTI) over the Earth surface [1]. The method was outlined, implemented and tested in a simplified reference scenario and the requirements for its applicability, in terms of minimum Clutter-to-Noise Ratio (CNR) and of Sea/Land backscattering coefficients difference, were highlighted [2].
The SLTI method is based on the a priori knowledge of the displacement of the sea-land tran- sitions within the radar coverage area through which a geographic reference mask for the received radar echo is defined. The CR is then provided by maximization of a time domain cross-correlation function between the received single frequency radar echo and the time mask that is obtained transforming the geographic reference mask in a time signal through a parametric ionospheric transformation.
In order to analyze the performance of the proposed SLTI method in realistic scenarios, also a software tool for the simulation of the received echo of an OTH SWR in pulse mode has been devel- oped [3]. The tool accounts for several models of the transmitted radar pulse, the antenna pattern, the electron ionospheric structure and the Sea/Land backscattering of the Earth’s surface [4]. The tool is based on a numerical model of the OTH SWR monostatic equation that has been developed and already presented by the same authors of this work in [2].
In this paper, we assume that the parametric ionospheric transformation is based on a look up table of 200 profiles of ionospheric equivalent reflection height versus elevation angle, computed assuming 200 vertical profiles of electronic density. For a given frequency and a given elevation angle, the ionospheric equivalent reflection height is computed by means of a ray tracing procedure applied to the electron density profile.
We recall the main characteristics of the SLTI method and we present some details of the end to end software simulator related to the core of the cross-correlation algorithm applied to the look up table of ionospheric equivalent reflection heights.
Finally, we present some simulation results for the Mediterranean scenario and some specific radar setup in order to discuss the CR performance of the SLTI for different configurations of the Sea/Land mask jointly with the ionospheric behavior.
## Over-the-horizon radar target registration improvement by terrain feature localization
仔细摘抄部分，
## High-frequency radar aircraft detection method based
Abstract: Aircraft detection is an important application of Wuhan Ionosonde Sounding System (WISS), which recently has been developed by the Ionospheric Laboratory of Wuhan University. Since the ionosphere varies temporally and spatially, severe multipath effects are produced, which jeopardise the characteristic quantities extracting of targets from the recorded data. To solve the above problems and further identify the targets from the fuzzy signals, this study presents a neural networks and time-frequency-based algorithm. By neural networks, the characteristic quantities of targets are extracted from the recorded data, and then, the Doppler spectrum of target signals is computed to determine the radial velocity of targets. Moreover, with the help of time-frequency analysis, the radial velocity variability in time domain can be identified, which finally leads to the identification of the type of the targets. Simulations using the recorded data of the WISS show that the type of the targets is aircraft and 90.9% accurate recognition of aircraft targets can be achieved.
  1 Introduction
With a long history, the high-frequency (HF) band (3–30 MHz) radar [1, 2] has been being particularly concerned for its important characteristics and widely applications, such as long-range target monitoring, airborne early warning, and anti-stealth detection. However, most of the large HF radars are equipped with large antenna arrays [3], whereas the Wuhan Ionosonde Sounding System (WISS) [4, 5] operating at HF has made improvements in many aspects, such as a low-power, a small size and a portable instrument. With the strictly synchronised time and clock in both transmitter and receiver, the WISS not only works well in ionospheric real-time detection [5], but also has ability to detect moving targets.
There are many ways to monitor aircrafts by the HF radar. In 1938, aircrafts were detected by the first operational military radar system installed by the British [6]. At HF frequencies transmitted signals follow either a ground-wave mode or a sky-wave mode. Under the ground-wave mode, electromagnetic waves follow the curvature of the earth along the air–water interface. As a successful case, the Northern Radar’s Cape Race Ground Wave Radar system operated in the autumn of 1990 [7]. Under the sky-wave mode, the Naval Research Laboratory conducted a definitive set of experiments that showed HF sky-wave radar could succeed in aircraft detection in 1956 [6]. In the autumn of 1961, a high-power transmitter and antenna suitable for testing the feasibility of aircraft detection were added. The aircraft had been detected and the range tracked over the major portion of their flights across the Atlantic [6].
Many techniques have been used in this radar target recognition. Statistical feature extraction and classification methods, such as bispectrum, polarisation matrix, Bayes probability algorithm and scattering matrix are used [8, 9] in some of these studies. However, these statistical methods are not robust to noises. Thus, the correct recognition rates of these studies are very low for these mixed-signals containing the clutter and the target signals, which is the common disadvantage of these statistical techniques for automatic target recognition studies. In some of these automatic radar target recognition studies, feature extraction is made by using these varied traditional signal-processing methods, such as Fourier transform, relational filtering, inverse Fourier transform, Mellin transform, fractal characterisation and fast Fourier transform (FFT) etc. [10]. In these signal-processing techniques, the time-frequency windows, with the same fixed width, are used for all of the frequency components in radar echo signals. Hence, based on the technique of time-frequency windows, a genetic wavelet neural network (WNN) model is developed for target recognition. And the recognition rate of this algorithm is about 90% for target subjects [11].
In this paper, a novel HF radar target recognition [12, 13] algorithm called neural networks and time-frequency (NNTF) is introduced for aircraft detection by a low-power bistatic HF radar. The NNTF algorithm consists of a back propagation (BP) neural network and a Choi–Williams distribution (CWD). For one thing, the BP neural network is based on the gradient descent method that minimises the sum of the squared errors between actual output values and desired output values. After testing the real radar echo
875 & The Institution of Engineering and Technology 2013www.ietdl.org
signals, the accuracy rate of aircraft targets identification can reach 90.9%. Thus, the NNTF algorithm could predict whether the echo signals have targets or not and prepare for precisely detecting targets for large radars. For another, the CWD is robust to noises; so this technique can be used for the feature extraction from the mixed-signals containing the clutter and the target signals. After the CWD, instant Doppler spectrum and radial velocity of target could be obtained. According to the radial velocity, the type of target could be judged.
This paper is organised as follows. In Section 2, the NNTF algorithm is introduced in detail. In Section 3, the experimental configuration is described, and training and testing results on the real data are presented. Finally, the conclusion is drawn in Section 4.
## Coordinate Registration Method based on Sea/Land Transitions Identification for Over-the-Horizon Sky-Wave Radar: Numerical Model and Basic Performance Requirements
The problem of range CR for single pulse OTHR-SW HF signals has been addressed, pursued by relying only on the geographical information about the actual position of coastlines and on the related variations of NRCS occurring in correspondence of sea/land transitions and affecting the backscattered radar signal. The solution proposed is based on the conversion of a geographic mask into a reference signal, dependent on the equivalent ionospheric reflection height, and on its correlation with the received radar signal.
In order to analyze this correlation-based solution, an extended numerical model was developed accounting for the radar-ionosphere-Earth interaction on the whole. The model generates the OTHR-SW HF signal as a coherent summation of different surface contributions, accounting for the main
radar, ionospheric and clutter parameters/effects (e.g., antenna radiation pattern, transmit pulse duration, time-varying ionospheric altitude, and time-varying surface response). It allows to analyze the performance of the correlation method under any condition of ionospheric and surface reflection space-time variability.
The main objective of this paper was to provide rough reference requirements (in terms of both SNR and differential sea/land NRCS) for a given range CR precision. For this purpose the model was exploited at a basic level by imposing some elementary,simplifying assumptions. In synthesis, it was shown that a differential sea/land NRCS of about 7 dB is needed in order to identify a single sea/land transition with a down-range estimation error of +10 km and that smaller differential NRCS levels lead to higher uncertainties. Incidentally, an error of +10 km is
of the same order of error magnitude found by Barnum and Simpson when comparing terrain features and beacon ground range displacements based on experimental data [24]. When passing from land to
sea, an NRCS change of at least 7 dB is expected. On the other hand, a +10 km error in the identification of a sea/land transition would be more than acceptable
in an OTHR-SW HF CR framework based on a single pulse analysis, considering also that several sea/land transition position estimates could be averaged
based on SLTI processing of signals coming from subsequent transmit pulses. Therefore, these results obtained in ideal conditions allow us to proceed with further analyses involving an increased parametric complexity of the ionospheric and clutter effects
(in particular, time and space varying ionospheric reflection height, multilevel sea/land NRCS, smooth sea/land transitions, multipath, different sea/land fluctuation statistics, etc.). 
We propose an approach to the problem of range coordinate registration (CR) for HF band over-the-horizon sky-wave radar (OTHR-SW) signals on a single pulse basis. The approach is based on the a priori knowledge of the displacement of the sea/land transitions within the area illuminated by the radar antenna beam. It takes advantage of the geomorphological structure of the surveillance area, which is exploited to build a surface correlation mask that is in turn used as a geographic reference for the received radar echo. The method is based on the maximization of the cross-correlation between the received radar echo and the surface mask signatures. We describe first an extended numerical model of the whole HF OTHR-SW scenario for simulating the received signal, then we show the results of the application of the method under simplifying operative hypotheses that allow to point out the minimum requirements in terms of received signal-to-noise ratio (SNR) and differential sea/land backscattering coefficient for achieving given accuracies in the range estimates.
I. INTRODUCTION
Though based on an assessed technology, OTHRs are attracting today much interest, thanks to the significant steps forward made by the signal processing and data storage techniques. In particular, OTHR-sky-wave systems (OTHR-SW hereafter) are the only ground-based sensors with a surveillance area comparable in surface with that of satellite constellations or airborne radar networks. This ability is achieved by exploiting the propagation characteristics of the ionosphere [1, 2] (Fig. 1 and Fig. 2 show, respectively, a 3D and a 2D sketch of the OTH-SW observation geometry). Nevertheless, the employment of the ionosphere as part of the Tx-Rx channel  introduces an intrinsic uncertainty about the actual HF wave propagation path and, consequently, about the actual geographic position of radar footprint pertinent to the echo received at a given instant and at a given antenna pointing direction. In fact,
the nonhomogeneous structure and time-dependent behavior of the onosphere   make the a priori models for the propagation channel absolutely useless for a correct georeferenciation of the received echo. The OTHR-SW system itself could be used in an ionospheric sounding mode, but this would periodically distract the system from its main observation mode, by significantly modifying its surveillance schedule. In this respect, for instance the French OTHR-SW Nostradamus system [12] is able to work in BSS mode (variable frequency backscattering sounding) and in ELS mode (variable elevation backscattering sounding). A complete characterization of the ionospheric reflection region can be achieved through these operational modes, at the expense of a distraction of the system from the main surveillance mode for intervals of the order of several minutes [12].
Another approach to the CR problem is merging OTHR-SW measurements and external data from independent sources (e.g., other OTHR-SW with partially overlapping coverage area [14—17], or advanced HF line-of-sight (LOS) receivers [18] or microwave radars located within the surveillance area [19]). The main problems related to this approach
are the difficulty to reach and maintain the required synchronization between the cooperating systems and to find an optimal arrangement of the advanced receivers.
Some other authors proposed that the CR task could be carried out by employing HF beacons or transponders arranged within the surveillance area
[20, 21, 19, 22, 23]. Also in this case, the main limitation is the need for a rather dense network
of beacons/transponders to be arranged within the surveillance area. For this reason, this procedure is typically used only in limited areas when assessing
the performance of different CR methods [24]. Also, sources of opportunity with a known geographic location (for instance, HF radio broadcasting antennas, noisy industrial or urban centers, etc.) or targets of opportunity equipped with a GPS device (airliners, cooperating ships, etc.) can be exploited for the CR procedure [24], leading to the same aforementioned problems.
Finally, a group of CR methods rely on the identification of known geomorphological patterns lying within the surveillance area and are not strictly dependent on information of an external nature
[24, 25]. The SLTI (sea/land transition identification) method we introduce in this paper belongs to this group. Its peculiarity is to identify the sea/land transitions through a correlation processing of each single radar sweep involving at least one coastal profile by exploiting the relatively sharp land/sea
HF reflectivity transitions. Being based on range processing only, SLTI is sensitive to the sea/land transitions that are orthogonal (or close to orthogonal) to the radar slant range direction. The reason of
such limitation, is that SLTI allows to perform the transitions’ identification on a single azimuthal pointing direction and not after the whole scan of the surveillance area has been completed, as typically done by the aforementioned methods based on
known geomorphological patterns. In this manner,
the SLTI method can process the radar signal within time intervals that are significantly smaller than
the coherence time of the ionosphere and can thus account for its azimuthal inhomogeneity. Evidently, the main drawback of the SLTI method is directly related to its procedure, namely that it detects sea/land transitions by range processing only, which may leave azimuth uncertainties in those cases where the antenna
pointing azimuth differs from the actual one, due
to the Earth’s magnetic field effect. For a generic azimuth, in fact, the joint effect of the magnetic
field and of the ionosphere is to induce a partially unknown azimuthal drift [26], which is negligible only when the azimuthal pointing direction runs parallel
to the Earth’s meridians. In principle, this problem can be faced by estimating the Earth’s magnetic
field effect, or even by repeating the SLTI range correlation procedure of the received radar sweep with several different geomorphological patterns associated to adjacent azimuthal directions, and finding the azimuth corresponding to the best correlation match. Clearly, this is subject to the presence of different easily recognizable patterns in the adjacent azimuth geomorphological profiles (e.g., significant difference of coastal distances and/or presence of islands).
In this paper we introduce a numerical model to generate simulated single pulse receive signals for
an OTHR-SW system and exploit it in a simplified reference scenario in order to derive the related basic performance of the SLTI method and requirements in terms of both signal-to-noise ratio (SNR) and differential sea/land normalized radar cross section (NRCS).
The paper is structured as follows. After having introduced the SLTI approach in Section II, in Section III we provide a formulation for the discrete representation of the expected power at the receiver versus time for a single pulse in transmission. This is exploited in Section IV to evaluate the SLTI under simplifying operative hypotheses in order to define the minimum requirements in terms of received SNR and differential sea/land backscattering coefficient. In Section V the conclusions are drawn and future perspectives for the simulation model outlined.
